---
exports:
  - format: pdf
    template: arxiv_nips
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Fixed point iterations

```{code-cell}
#%config InlineBackend.figure_format = 'svg'
from pylab import *
```

## Newton as fixed point iteration

The Newton-Raphson method to find the zeros of $f(x)$ can be written as

$$
x_{n+1} = \phi(x_n), \qquad \phi(x) = x - \frac{f(x)}{f'(x)}
$$ 

At a root $\alpha$, we have

$$
f(\alpha) = 0, \qquad \phi(\alpha) = \alpha - \frac{f(\alpha)}{f'(\alpha)} = \alpha
$$

Thus the root is a fixed point of the function $\phi$. We have converted
the problem of root finding into one of finding the fixed points of a
map via the *fixed point iteration* $x_{n+1} = \phi(x_n)$.

:::{prf:example}
To find $\sqrt{a}$ for $a > 0$, we can find the roots of $f(x) = x^2 - a$. We can rewrite this as a fixed point relation in many ways, e.g.,

1.  $x = x + c(x^2 - a)$ for some $c \ne 0$

2.  $x = \frac{a}{x}$

3.  $x = \half(x + \frac{a}{x})$, which is Newton method.

Not all these fixed point iterations may converge.

```{code-cell}
a = 3.0
c = 0.1
x1, x2, x3 = 2.0, 2.0, 2.0
print("%6d %18.10e %18.10e %18.10e" % (0,x1,x2,x3))
for i in range(10):
    x1 = x1 + c*(x1**2 - a)
    x2 = a/x2
    x3 = 0.5*(x3 + a/x3)
    print("%6d %18.10e %18.10e %18.10e" % (i+1,x1,x2,x3))
```

Only the third form, the Newton-Method, is converging to the root.
:::

## Fixed point, contraction map

:::{prf:theorem}
Let $\phi : [a,b] \to [a,b]$ be continuous. Then $x = \phi(x)$ has
atleast one solution in $[a,b]$.
:::

:::{prf:proof}
Consider the continuous function 

$$
h(x) = \phi(x) - x
$$ 

for which 

$$
h(a) = \phi(a) - a \ge 0, \qquad h(b) = \phi(b) - b \le 0
$$ 

By intermediate value theorem, $h(x)$ must have atleast one root in
$[a,b]$, which is also the fixed point of $\phi(x)$.
:::

:::{prf:theorem} Contraction map
Let $\phi : [a,b] \to [a,b]$ be continuous and for some $\lambda \in (0,1)$

$$
|\phi(x) - \phi(y)| \le \lambda |x-y|, \quad \forall x, y \in [a,b]
$$

Then $x=\phi(x)$ has a unique solution $\alpha \in [a,b]$. Also, the iterates 

$$
x_n = \phi(x_{n-1}), \qquad n \ge 1
$$ 

will converge to $\alpha$ for any choice of $x_0 \in [a,b]$ and

$$
|\alpha - x_n| \le \frac{\lambda^n}{1-\lambda} |x_1 - x_0|
$$

:::

:::{prf:proof}
**Uniqueness.** Suppose $\phi$ has two fixed points $\alpha, \beta \in [a,b]$. Then

$$
|\alpha - \beta| = |\phi(\alpha) - \phi(\beta)| \le \lambda |\alpha - \beta|
$$

and hence 

$$
(1-\lambda) |\alpha - \beta| \le 0
$$ 

Since $0 < \lambda < 1$, we conclude that only equality is possible, which
implies that $\alpha  =\beta$.

**Convergence.** Since $\phi([a,b]) \subset [a,b]$, the
sequence generated by $x_n = \phi(x_{n-1})$ is contained in $[a,b]$.

$$
|\alpha - x_{n+1}| = |\phi(\alpha) - \phi(x_n)| \le \lambda |\alpha - x_n|
$$

and by induction 

$$
|\alpha - x_n| \le \lambda^n |\alpha - x_0|
\label{eq:contineq}
$$ 

As $n \to \infty$, $\lambda^n \to 0$ so that $x_n \to \alpha$.

**Error bound.** Using contraction property and triangle inequality, we have

$$
|\alpha - x_0| \le |\alpha - x_1| + |x_1 - x_0| \le \lambda |\alpha - x_0| + |x_1 - x_0|
$$

and hence 

$$
|\alpha - x_0| \le \frac{1}{1-\lambda} |x_1 - x_0|
\label{eq:cont01}
$$ 

Combining this withÂ [](#eq:contineq), we get

$$
|\alpha - x_n| \le \lambda^n |\alpha - x_0| \le \frac{\lambda^n}{1-\lambda} |x_1 - x_0|
$$

:::

:::{prf:remark}
The inequality

$$
|\alpha - x_{n+1}| = |\phi(\alpha) - \phi(x_n)| \le \lambda |\alpha - x_n|, \qquad \lambda \in (0,1)
$$ 

shows that the sequence $\{x_n\}$ is atleast linearly convergent, with rate of
convergence bounded by $\lambda$.
:::

:::{prf:remark}
We can derive an error estimate as follows. Similar to [](#eq:cont01), we can show that

$$
|\alpha - x_n| \le \frac{1}{1-\lambda} |x_{n+1} - x_n|
$$ 

and hence

$$
|\alpha - x_{n+1}| \le \lambda |\alpha - x_n| \le \frac{\lambda}{1-\lambda} |x_{n+1} - x_n|
$$ 

which is a more sharper error bound since $\lambda < 1$. If

$$
\frac{\lambda}{1-\lambda} |x_{n+1} - x_n| \le \epsilon \limplies
|\alpha - x_{n+1}| \le \epsilon
$$

:::

## Differentiability and contractivity

:::{prf:theorem}
Assume that $\phi : [a,b] \to [a,b]$ is continuously differentiable and

$$
\lambda = \max_{a \le x \le b} |\phi'(x)| < 1
$$ 

Then

1.  $\phi$ has a unique fixed point $\alpha \in [a,b]$.

2.  For any $x_0 \in [a,b]$, the iterations $x_{n+1} = \phi(x_{n})$
    converge to $\alpha$.

3.  $|\alpha - x_n| \le \lambda^n |\alpha - x_0| \le \frac{\lambda^n}{1-\lambda} |
    x_1 - x_0|$ and
    $$\lim_{n \to \infty} \frac{\alpha - x_{n+1}}{\alpha - x_n} = \phi'(\alpha)$$
:::

:::{prf:proof}
(1,2) For some $\xi$ between $x$, $y$, we have

$$
\phi(x) - \phi(y) = \phi'(\xi) (x-y)
$$ 

and hence

$$
|\phi(x) - \phi(y)| = |\phi'(\xi)| |x-y| \le \lambda |x-y|
$$ 

so that $\phi$ is a contraction map and by previous theorem, (1) and (2) follow.

\(3\) Now

$$
\alpha - x_{n+1} = \phi(\alpha) - \phi(x_n) = \phi'(\xi_n) (\alpha - x_n), \qquad \xi_n \textrm{ between } \alpha, x_n
$$ 

and $\xi_n \to \alpha$ so that

$$
\lim_{n \to \infty} \frac{\alpha - x_{n+1}}{\alpha - x_n} = \lim_{n \to \infty}
\phi'(\xi_n) = \phi'(\alpha)
$$ 

If $\phi'(\alpha) \ne 0$, then the sequence $\{ x_n \}$ converges to $\alpha$ with order $p=1$, i.e., we have linear convergence.
:::

:::{prf:theorem}
Let $\alpha$ be a fixed point of $\phi$ and suppose $\phi$ is continuously differentiable in some neighbourhood of $\alpha$ with $|\phi'(\alpha)| < 1$. Then the results of previous theorem still hold provided $x_0$ is sufficiently close to $\alpha$.
:::

:::{prf:proof}
Pick a number $\lambda$ satisfying

$$
|\phi'(\alpha)| < \lambda < 1
$$ 

Then pick an interval $I = [\alpha - \delta, \alpha + \delta]$ such that

$$
\max_{x \in I} |\phi'(x)| \le \lambda < 1
$$ 

Now for any $x \in I$, $|\alpha - x| \le \delta$ and

$$
|\alpha - \phi(x)| = |\phi(\alpha) - \phi(x)| = |\phi'(\xi)| \cdot |\alpha - x|
$$

where $\xi$ is between $\alpha, x$ and hence in $I$, so that

$$
|\alpha - \phi(x)| \le \lambda |\alpha - x| < |\alpha - x| \le \delta
$$

Hence we have $\phi(I) \subset I$. Now apply previous theorem using $[a,b] = [\alpha- \delta,\alpha+\delta]$.
:::

:::{prf:remark}
The condition $|\phi'(\alpha)| < 1$ ensures that the iterations
$x_{n+1} = \phi(x_j)$ converge atleast linearly if we start close enough
to the root.
:::

:::{prf:example}
To find the root of $f(x)=x^2-a$, we have tried the following

$$
x_{n+1} = \phi(x_n), \qquad \phi(x) = x + c(x^2 -a), \qquad c = 0.1
$$ 

which did not converge. We need

$$
|\phi'(\sqrt{a})| = |1 + 2 c \sqrt{a}| < 1 \Longrightarrow - \frac{1}{\sqrt{a}} < c < 0
$$

For $a=3$, the good values are $c \in (-0.578, 0.0)$, so try with
$c=-0.1$ for example.
:::

## Order of convergence

If $\phi'(\alpha) \ne 0$, then we only get linear convergence. For faster convergence, derivatives of $\phi$ need to vanish at the root.

:::{prf:theorem}
Let $\alpha$ be a fixed point of $\phi$ and let $\phi$ be $p$ times continuously differentiable around $\alpha$, for some $p \ge 2$.  Further, assume

\begin{gather}
\phi'(\alpha) = \phi''(\alpha) = \ldots = \phi^{(p-1)}(\alpha) = 0 \\
\phi^{(p)}(\alpha) \ne 0
\end{gather}

Then if the initial guess $x_0$ is sufficiently close to $\alpha$, the iteration $x_{n+1} = \phi(x_n)$ will have order of convergence $p$ and

$$
\lim_{n \to \infty} \frac{\alpha - x_{n+1}}{(\alpha - x_n)^p} = (-1)^{p-1}
\frac{\phi^{(p)}(\alpha)}{p!}
$$

:::

:::{prf:proof}
Since $\phi'(\alpha) = 0$, we can choose an interval $I = [\alpha-\delta,\alpha+\delta]$ in which $|\phi'(x)| < 1$. Using previous theorem, we know the iterations converge for any initial guess $x_0 \in I$.

Now by Taylor expansion around $\alpha$ 

$$
\begin{aligned}
 x_{n+1} 
 &= \phi(x_n) \\
 &= \phi(\alpha) + (x_n-\alpha) \phi'(\alpha) + \ldots + \frac{(x_n-\alpha)^{p-1}} {(p-1)!} \phi^{(p-1)}(\alpha) \\
& \quad + \frac{(x_n-\alpha)^p}{p!} \phi^{(p)}(\xi_n), \qquad \textrm{$\xi_n$ between $x_n$ and $\alpha$}
\end{aligned}
$$ 

Using the given conditions on $\phi$

$$
x_{n+1} = \alpha + \frac{(x_n-\alpha)^p}{p!} \phi^{(p)}(\xi_n)
$$ 

and hence we have $p$'th order convergence

$$
|x_{n+1} - \alpha| \le M |x_n-\alpha|^p, \qquad M = \frac{1}{p!} \max |\phi^{(p)}|
$$

The last result also follows easily since $\xi_n \to \alpha$.
:::

:::{prf:example} Newton-Raphson method
The iteration function for Newton-Raphson method is

$$
\phi(x) = x - \frac{f(x)}{f'(x)}
$$ 

for which

$$
\phi'(x) = \frac{f(x) f''(x)}{[f'(x)]^2}, \qquad
\phi''(x) = \frac{f''(x)}{f'(x)} + \frac{f(x) f'''(x)}{[f'(x)]^2} - \frac{2 f(x) [f''(x)]^2}{[f'(x)]^3}
$$ 

If $f'(\alpha) \ne 0$, then 

$$
\phi'(\alpha) = 0, \qquad \phi''(\alpha) = \frac{f''(\alpha)}{f'(\alpha)}
$$ 

and hence Newton method converges with order atleast $p=2$.
:::

:::{prf:example}
Consider the function

$$
f(x) = (x-1)^2 \sin(x)
$$

for which $x=1$ is a double root.

```{code-cell}
def f(x):
    return (x-1.0)**2 * sin(x)

def df(x):
    return 2.0*(x-1.0)*sin(x) + (x-1.0)**2 * cos(x)

x = linspace(0.0,2.0,100)
plot(x,f(x)), xlabel('x'), ylabel('f(x)'), grid(True);
```

Here is the Newton method

```{code-cell}
def newton(x0,m=1.0):
    n = 50
    x = zeros(50)
    x[0] = x0
    print("%6d %24.14e" % (0,x[0]))
    for i in range(1,50):
        x[i] = x[i-1] - m*f(x[i-1])/df(x[i-1])
        if i > 1:
            r = (x[i] - x[i-1])/(x[i-1]-x[i-2])
        else:
            r = 0.0
        print("%6d %24.14e %14.6e" % (i,x[i],r))
        if abs(f(x[i])) < 1.0e-14:
            break
```

The Newton method gives

```{code-cell}
newton(2.0)
```

which shows convergence towards $x=1$. Note that

$$
\phi'(1) =  \frac{f(1) f''(1)}{[f'(1)]^2} = \half < 1
$$

Consistent with this, we observe that Newton method is converging but only linearly;  the last column above shows that

$$
\frac{|x_{n+1} - x_n|}{|x_n - x_{n-1}|} \approx \half = \phi'(1), \qquad n \to \infty
$$

:::

## Multiple roots and Newton method

Let $\alpha$ be a root of $f(x)$ with multiplicity $m$, so that

$$
f(\alpha) = f'(\alpha) = \ldots = f^{(m-1)}(\alpha) = 0, \qquad f^{(m)}(\alpha) \ne 0
$$

A Taylor expansion around $\alpha$ gives

$$
f(x) = \frac{(x-\alpha)^m}{m!} f^{(m)}(\xi_x), \qquad \textrm{$\xi_x$ between $
\alpha$ and $x$}
$$ 

Near $\alpha$, $f(x)$ behaves like

$$
f(x) = (x-\alpha)^m h(x), \qquad h(\alpha) \ne 0
$$ 

Let us apply Newton method to this function. Since

$$
f'(x) = (x-\alpha)^m h'(x) + m(x-\alpha)^{m-1} h(x)
$$ 

so that the iteration function of Newton method is

$$
\phi(x) = x - \frac{f(x)}{f'(x)} = x - \frac{(x-\alpha) h(x)}{mh(x) + (x-\alpha)h'(x)}
$$

This satisfies

$$
\phi'(\alpha) = 1 - \frac{1}{m} \ne 0 \qquad \textrm{if} \quad m \ge 2
$$

Thus Newton method converges since $|\phi'(\alpha)| < 1$, but only linearly, with rate of convergence $c = \frac{m-1}{m}$.

To improve Newton method for multiple roots, we need an iteration function with $\phi'(\alpha) = 0$. This is satisfied for

$$
\phi(x) = x - m \frac{f(x)}{f'(x)}
$$ 

and

$$
\lim_{n \to \infty} \frac{\alpha - x_{n+1}}{(\alpha - x_n)^2} = - \half \phi''(\alpha)
$$

which recovers the quadratic convergence of Newton method.

:::{prf:example}
We repeat previous example but with $m=2$ since we have a double root

```{code-cell}
newton(2.0, m=2)
```

Now we recover quadratic convergence which is clearly faster than linear convergence !!! Compare the number of correct decimal places in the root between the two methods.
:::

The view point of fixed point iterations helped us to understand why Newton converges only linearly to multiple roots, and also helped to fix it so that quadratic convergence is recovered.

:::{prf:remark}
Note that $f'(x_n) \to 0$ as $x_n \to \alpha$, a multiple root. We have to be careful in applying Newton method since we divide by $f'(x_n)$. In the unlikely case that the denominator becomes exactly zero, it may generate inf or NaN.
:::
